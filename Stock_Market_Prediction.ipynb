{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e37adf-3929-47e6-8c38-9012056c17d4",
   "metadata": {},
   "source": [
    "# NUMPY PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5da12b-9400-4586-8006-8309ce7a287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after loading from CSV:\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2024-05-15  187.910004  190.649994  187.369995  189.720001  189.720001   \n",
      "2024-05-16  190.470001  191.100006  189.660004  189.839996  189.839996   \n",
      "2024-05-17  189.509995  190.809998  189.179993  189.869995  189.869995   \n",
      "2024-05-20  189.330002  191.919998  189.009995  191.039993  191.039993   \n",
      "2024-05-21  191.089996  192.729996  190.919998  192.350006  192.350006   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2024-05-15  70400000  \n",
      "2024-05-16  52845200  \n",
      "2024-05-17  41282900  \n",
      "2024-05-20  44361300  \n",
      "2024-05-21  42309400  \n",
      "Data after dropping NA:\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2024-05-15  187.910004  190.649994  187.369995  189.720001  189.720001   \n",
      "2024-05-16  190.470001  191.100006  189.660004  189.839996  189.839996   \n",
      "2024-05-17  189.509995  190.809998  189.179993  189.869995  189.869995   \n",
      "2024-05-20  189.330002  191.919998  189.009995  191.039993  191.039993   \n",
      "2024-05-21  191.089996  192.729996  190.919998  192.350006  192.350006   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2024-05-15  70400000  \n",
      "2024-05-16  52845200  \n",
      "2024-05-17  41282900  \n",
      "2024-05-20  44361300  \n",
      "2024-05-21  42309400  \n",
      "Data after normalization:\n",
      "        Open      High       Low     Close  Adj Close    Volume\n",
      "0  0.000000  0.031246  0.172492  0.519195   0.519195  1.000000\n",
      "1  0.587155  0.232144  0.706295  0.541132   0.541132  0.508977\n",
      "2  0.366970  0.102677  0.594404  0.546616   0.546616  0.185570\n",
      "3  0.325688  0.598211  0.554777  0.760510   0.760510  0.271675\n",
      "4  0.729356  0.959817  1.000000  1.000000   1.000000  0.214282\n",
      "Data after feature engineering:\n",
      " Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume, MA10, MA50]\n",
      "Index: []\n",
      "No data available after preprocessing. Please check your dataset and preprocessing steps.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Data Collection (from CSV)\n",
    "def get_stock_data(file_path):\n",
    "    data = pd.read_csv(file_path, index_col='Date', parse_dates=True, dayfirst=True)\n",
    "    print(\"Data after loading from CSV:\\n\", data.head())\n",
    "    return data\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    data = data.dropna()\n",
    "    print(\"Data after dropping NA:\\n\", data.head())\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    print(\"Data after normalization:\\n\", scaled_data.head())\n",
    "    \n",
    "    return scaled_data, scaler\n",
    "\n",
    "# Feature Engineering\n",
    "def create_features(data):\n",
    "    data['MA10'] = data['Close'].rolling(window=10).mean()\n",
    "    data['MA50'] = data['Close'].rolling(window=50).mean()\n",
    "    data = data.dropna()\n",
    "    print(\"Data after feature engineering:\\n\", data.head())\n",
    "    return data\n",
    "\n",
    "# Model Selection and Training\n",
    "def train_models(X_train, y_train):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(),\n",
    "        \"Neural Network\": MLPRegressor(hidden_layer_sizes=(50,50,50), max_iter=500)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        models[name] = model\n",
    "        \n",
    "    return models\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    evaluation = {}\n",
    "    for name, model in models.items():\n",
    "        predictions = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        evaluation[name] = mse\n",
    "    return evaluation\n",
    "\n",
    "# Prediction and Visualization\n",
    "def predict_and_visualize(models, X_test, y_test, scaler, original_data):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    for name, model in models.items():\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = scaler.inverse_transform(np.hstack((np.zeros((predictions.shape[0], original_data.shape[1] - 1)), predictions.reshape(-1, 1))))[:, -1]\n",
    "        \n",
    "        plt.plot(original_data.index[-len(predictions):], predictions, label=f'{name} Predictions')\n",
    "    \n",
    "    plt.plot(original_data['Close'], label='Actual Prices')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.title('Stock Price Prediction')\n",
    "    plt.show()\n",
    "\n",
    "# Future Prediction\n",
    "def future_prediction(models, latest_data, scaler, future_periods=7):\n",
    "    # Generate future dates for prediction\n",
    "    future_dates = pd.date_range(start=latest_data.index[-1], periods=future_periods + 1, freq='D')[1:]\n",
    "    \n",
    "    # Create future features\n",
    "    future_features = pd.DataFrame(index=future_dates)\n",
    "    future_features['MA10'] = latest_data['Close'].rolling(window=10).mean().iloc[-1]\n",
    "    future_features['MA50'] = latest_data['Close'].rolling(window=50).mean().iloc[-1]\n",
    "    \n",
    "    # Scale the features\n",
    "    future_features_scaled = scaler.transform(future_features)\n",
    "    \n",
    "    # Make predictions for future periods\n",
    "    future_predictions = {}\n",
    "    for name, model in models.items():\n",
    "        predictions = model.predict(future_features_scaled)\n",
    "        predictions = scaler.inverse_transform(np.hstack((np.zeros((predictions.shape[0], latest_data.shape[1] - 1)), predictions.reshape(-1, 1))))[:, -1]\n",
    "        future_predictions[name] = predictions\n",
    "    \n",
    "    return future_dates, future_predictions\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Parameters\n",
    "    file_path = r'C:\\Users\\Abi Karimireddy\\Downloads\\AAPL(2).csv'  # Update this path to your CSV file\n",
    "    \n",
    "    # Data Collection\n",
    "    data = get_stock_data(file_path)\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    preprocessed_data, scaler = preprocess_data(data)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    feature_data = create_features(preprocessed_data)\n",
    "    \n",
    "    # Preparing training and testing data\n",
    "    X = feature_data.drop(['Close'], axis=1)\n",
    "    y = feature_data['Close']\n",
    "    \n",
    "    # Ensure there is enough data to split\n",
    "    if len(X) == 0 or len(y) == 0:\n",
    "        print(\"No data available after preprocessing. Please check your dataset and preprocessing steps.\")\n",
    "        return\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Model Selection and Training\n",
    "    models = train_models(X_train, y_train)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    evaluation = evaluate_models(models, X_test, y_test)\n",
    "    for name, mse in evaluation.items():\n",
    "        print(f'{name}: Mean Squared Error = {mse}')\n",
    "    \n",
    "    # Prediction and Visualization\n",
    "    predict_and_visualize(models, X_test, y_test, scaler, data)\n",
    "    \n",
    "    # Future Prediction\n",
    "    future_dates, future_predictions = future_prediction(models, data, scaler, future_periods=7)\n",
    "    print(\"\\nFuture Predictions:\")\n",
    "    for name, predictions in future_predictions.items():\n",
    "        print(f'{name} Predictions for the next 7 days:', predictions)\n",
    "    \n",
    "    print(\"\\nFuture Dates for Prediction:\", future_dates)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f1f4f-707b-4632-8df0-56eae6611738",
   "metadata": {},
   "source": [
    "# Process Explanation\n",
    "\n",
    "## Data Loading and Preprocessing\n",
    "\n",
    "### Data Loading\n",
    "- The data is loaded from a CSV file using pandas' `read_csv()` function.\n",
    "- The `index_col='Date'` parameter specifies that the 'Date' column should be used as the index.\n",
    "- The `parse_dates=True` parameter ensures that dates are parsed as datetime objects.\n",
    "- The `dayfirst=True` parameter specifies that the day comes before the month in the date format.\n",
    "\n",
    "### Data Preprocessing\n",
    "- Missing values are handled by dropping rows with NaN values using the `dropna()` function.\n",
    "- The data is normalized using Min-Max scaling to scale all features to a range between 0 and 1.\n",
    "- The MinMaxScaler from sklearn.preprocessing is used for normalization.\n",
    "\n",
    "## Feature Engineering\n",
    "- Two moving averages (MA10 and MA50) are calculated as additional features.\n",
    "- Moving averages are calculated using the `rolling()` function followed by `mean()`.\n",
    "- Rows with NaN values resulting from the feature calculation are dropped.\n",
    "\n",
    "## Model Selection and Training\n",
    "\n",
    "### Models Used\n",
    "- Three regression models are selected: Linear Regression, Decision Tree Regressor, and MLP Regressor (Neural Network).\n",
    "\n",
    "### Training\n",
    "- The selected models are trained using the training data.\n",
    "- Training is done using the `fit()` function.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "### Evaluation Metric\n",
    "- Mean Squared Error (MSE) is used as the evaluation metric to assess the performance of each model.\n",
    "\n",
    "### Evaluation Process\n",
    "- The trained models are evaluated using the test data.\n",
    "- Mean Squared Error (MSE) is calculated using the `mean_squared_error()` function from sklearn.metrics.\n",
    "\n",
    "## Prediction and Visualization\n",
    "\n",
    "### Prediction\n",
    "- The trained models are used to make predictions on the test data.\n",
    "- Predictions are made using the `predict()` function for each model.\n",
    "\n",
    "### Visualization\n",
    "- Predicted stock prices are plotted along with actual prices for visualization.\n",
    "- Matplotlib is used for data visualization.\n",
    "\n",
    "# Result Analysis\n",
    "\n",
    "## Data after loading from CSV:\n",
    "| Date       | Open       | High       | Low        | Close      | Adj Close  | Volume    |\n",
    "|------------|------------|------------|------------|------------|------------|-----------|\n",
    "| 2024-05-15 | 187.910004 | 190.649994 | 187.369995 | 189.720001 | 189.720001 | 70400000  |\n",
    "| 2024-05-16 | 190.470001 | 191.100006 | 189.660004 | 189.839996 | 189.839996 | 52845200  |\n",
    "| 2024-05-17 | 189.509995 | 190.809998 | 189.179993 | 189.869995 | 189.869995 | 41282900  |\n",
    "| 2024-05-20 | 189.330002 | 191.919998 | 189.009995 | 191.039993 | 191.039993 | 44361300  |\n",
    "| 2024-05-21 | 191.089996 | 192.729996 | 190.919998 | 192.350006 | 192.350006 | 42309400  |\n",
    "\n",
    "## Data after dropping NA:\n",
    "| Date       | Open       | High       | Low        | Close      | Adj Close  | Volume    |\n",
    "|------------|------------|------------|------------|------------|------------|-----------|\n",
    "| 2024-05-15 | 187.910004 | 190.649994 | 187.369995 | 189.720001 | 189.720001 | 70400000  |\n",
    "| 2024-05-16 | 190.470001 | 191.100006 | 189.660004 | 189.839996 | 189.839996 | 52845200  |\n",
    "| 2024-05-17 | 189.509995 | 190.809998 | 189.179993 | 189.869995 | 189.869995 | 41282900  |\n",
    "| 2024-05-20 | 189.330002 | 191.919998 | 189.009995 | 191.039993 | 191.039993 | 44361300  |\n",
    "| 2024-05-21 | 191.089996 | 192.729996 | 190.919998 | 192.350006 | 192.350006 | 42309400  |\n",
    "\n",
    "## Data after normalization:\n",
    "| Date       | Open       | High       | Low        | Close      | Adj Close  | Volume    |\n",
    "|------------|------------|------------|------------|------------|------------|-----------|\n",
    "| 0.000000   | 0.031246   | 0.172492   | 0.519195   | 0.519195   | 1.000000   |\n",
    "| 0.587155   | 0.232144   | 0.706295   | 0.541132   | 0.541132   | 0.508977   |\n",
    "| 0.366970   | 0.102677   | 0.594404   | 0.546616   | 0.546616   | 0.185570   |\n",
    "| 0.325688   | 0.598211   | 0.554777   | 0.760510   | 0.760510   | 0.271675   |\n",
    "| 0.729356   | 0.959817   | 1.000000   | 1.000000   | 1.000000   | 0.214282   |\n",
    "\n",
    "## Data after feature engineering:\n",
    "Empty DataFrame\n",
    "Columns: [Open, High, Low, Close, Adj Close, Volume, MA10, MA50]\n",
    "Index: []\n",
    "No data available after preprocessing. Please check your dataset and preprocessing steps.\n",
    "\n",
    "## Model Performance:\n",
    "- The Mean Squared Error (MSE) is calculated for each model on the test data.\n",
    "- Lower MSE values indicate better performance of the model.\n",
    "\n",
    "### Linear Regression:\n",
    "- Mean Squared Error = [MSE value]\n",
    "\n",
    "### Decision Tree Regressor:\n",
    "- Mean Squared Error = [MSE value]\n",
    "\n",
    "### MLP Regressor (Neural Network):\n",
    "- Mean Squared Error = [MSE value]\n",
    "\n",
    "## Visualization:\n",
    "- Actual stock prices and predicted prices are plotted to visually assess the accuracy of the models.\n",
    "\n",
    "## Future Prediction:\n",
    "- Future stock prices are predicted for the next 7 days using the trained models.\n",
    "- Future dates for prediction are [Future Dates].\n",
    "- Predictions for each model:\n",
    "\n",
    "### Linear Regression:\n",
    "- Predictions for the next 7 days: [Predicted Prices]\n",
    "\n",
    "### Decision Tree Regressor:\n",
    "- Predictions for the next 7 days: [Predicted Prices]\n",
    "\n",
    "### MLP Regressor (Neural Network):\n",
    "- Predictions for the next 7 days: [Predicted Prices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b4c52-f0c8-4759-a3dc-f7cbacf6b392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
